#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <unistd.h>
#include <time.h>

#include "temperature_grid.h"
#include "temperature.h"
#include "gpu.h"

unsigned char rk4_cl[] = {
#include "rk4_kernel_str.c"
};

static gpu_config_t* current_gpu_config = NULL;

/* default thermal configuration parameters	*/
gpu_config_t default_gpu_config(void)
{
	gpu_config_t config;
	
	config.gpu_enabled = 0;
	config.platform_id = 0;
	config.device_id = 0;
	config.local_work_size[0] = 16;
	config.local_work_size[1] = 16;
	config.global_work_size[0] = 0; // to be determined by the grid size
	config.global_work_size[1] = 0;
	
	config.h_cuboid_reference = -1;
	config.pinned_h_cuboid = NULL;

	/* rk4_cl is a string generated by rk4.cl */
	config._cl_kernel_string = rk4_cl;
	config._cl_kernel_size = sizeof(rk4_cl);
	config._cl_kernel_rk4 = NULL;
	config._cl_context = NULL;
	config._cl_program = NULL;
	config._cl_queue = NULL;

	return config;
}

/* 
 * parse a table of name-value string pairs and add the configuration
 * parameters to 'config'
 */
void gpu_config_from_strs(gpu_config_t *config, str_pair *table, int size)
{
	int idx;
	if ((idx = get_str_index(table, size, "gpu_enable")) >= 0) {
		if(sscanf(table[idx].value, "%d", &config->gpu_enabled) != 1)
			fatal("invalid format for configuration parameter gpu_enable\n");
	}
	if ((idx = get_str_index(table, size, "gpu_platform")) >= 0) {
		if(sscanf(table[idx].value, "%d", &config->platform_id) != 1)
			fatal("invalid format for configuration parameter gpu_platform\n");
	}
	if ((idx = get_str_index(table, size, "gpu_device")) >= 0) {
		if(sscanf(table[idx].value, "%d", &config->device_id) != 1)
			fatal("invalid format for configuration parameter gpu_device\n");
	}
}

/* 
 * convert config into a table of name-value pairs. returns the no.
 * of parameters converted
 */
int gpu_config_to_strs(gpu_config_t *config, str_pair *table, int max_entries)
{
	if (max_entries < 3)
		fatal("not enough entries in table for gpu_config_to_strs()\n");

	sprintf(table[0].name, "gpu_enable");
	sprintf(table[1].name, "gpu_platform");
	sprintf(table[2].name, "gpu_device");

	sprintf(table[0].value, "%d", config->gpu_enabled);
	sprintf(table[1].value, "%d", config->platform_id);
	sprintf(table[2].value, "%d", config->device_id);

	return 3;
}

void gpu_copy_constants(gpu_config_t *config, grid_model_t *model)
{
	int i, max_layers;
	config->model.n_layers = model->n_layers;
	config->model.rows = model->rows;
	config->model.cols = model->cols;
	config->model.width = model->width;
	config->model.height = model->height;
	config->model.total_n_blocks = model->total_n_blocks;
	config->model.r_ready = model->r_ready;
	config->model.c_ready = model->c_ready;
	config->model.has_lcf = model->has_lcf;
	config->model.base_n_units = model->base_n_units;
	memcpy(&config->model.pack, &model->pack, sizeof(gpu_package_RC_t));
	memcpy(&config->model.config, &model->config, sizeof(gpu_thermal_config_t));
	if (model->config.model_secondary)
	{
		max_layers = model->n_layers + DEFAULT_PACK_LAYERS;
	}
	else
	{
		max_layers = model->n_layers + DEFAULT_PACK_LAYERS + SEC_PACK_LAYERS;
	}
	config->layer = (gpu_layer_t*) calloc(max_layers, sizeof(gpu_layer_t));
	config->layer_size = max_layers * sizeof(gpu_layer_t);
	for(i = 0; i < max_layers; ++i)
	{
		config->layer[i].no = model->layers[i].no;
		config->layer[i].has_lateral = model->layers[i].has_lateral;
		config->layer[i].has_power = model->layers[i].has_power;
		config->layer[i].k = model->layers[i].k;
		config->layer[i].k1 = model->layers[i].k1;
		config->layer[i].thickness = model->layers[i].thickness;
		config->layer[i].sp = model->layers[i].sp;
		config->layer[i].sp1 = model->layers[i].sp1;
		config->layer[i].rx = model->layers[i].rx;
		config->layer[i].ry = model->layers[i].ry;
		config->layer[i].rz = model->layers[i].rz;
		config->layer[i].rx1 = model->layers[i].rx1;
		config->layer[i].ry1 = model->layers[i].ry1;
		config->layer[i].rz1 = model->layers[i].rz1;
		config->layer[i].c = model->layers[i].c;
		config->layer[i].c1 = model->layers[i].c1;
	}
}

void gpu_check_error(int err, char* msg)
{
	if (err < 0)
	{
		printf("%s\n. (Error no.: %d)\n",msg, err);
		fatal("OpenCL Runtime Error.");
	}
}

void gpu_create_buffers(gpu_config_t *config, grid_model_t *model)
{
	int err;
	size_t element_size = sizeof(double); // TODO: support single precision
	config->element_size = element_size;
	config->extra_size = ((model->config.model_secondary)? EXTRA + EXTRA_SEC : EXTRA) * element_size;
	config->cuboid_size = model->rows * model->cols * model->n_layers * element_size;
	config->vector_size = config->extra_size + config->cuboid_size;

	/* we initialize memory to NaN. If the kernel has unexpected accesses, NaN will propagate. */
	double pattern = NAN;
	/* prepare device memory */
	config->d_v = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE, config->vector_size, NULL, &err);
	err |= clEnqueueFillBuffer(config->_cl_queue, config->d_v, &pattern, element_size, 0, config->vector_size, 0, NULL, NULL);
	gpu_check_error(err, "clCreateBuffer() for d_v failed.");
	config->d_dv = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE, config->vector_size, NULL, &err);
	err |= clEnqueueFillBuffer(config->_cl_queue, config->d_dv, &pattern, element_size, 0, config->vector_size, 0, NULL, NULL);
	gpu_check_error(err, "clCreateBuffer() for d_dv failed.");
	config->d_p_cuboid = clCreateBuffer(config->_cl_context, CL_MEM_READ_ONLY, config->vector_size, NULL, &err);
	err |= clEnqueueFillBuffer(config->_cl_queue, config->d_p_cuboid, &pattern, element_size, 0, config->vector_size, 0, NULL, NULL);
	gpu_check_error(err, "clCreateBuffer() for d_p_cuboid failed.");
	config->d_y = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE, config->vector_size, NULL, &err);
	err |= clEnqueueFillBuffer(config->_cl_queue, config->d_y, &pattern, element_size, 0, config->vector_size, 0, NULL, NULL);
	gpu_check_error(err, "clCreateBuffer() for d_y failed.");
	config->d_ytemp = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE, config->vector_size, NULL, &err);
	err |= clEnqueueFillBuffer(config->_cl_queue, config->d_ytemp, &pattern, element_size, 0, config->vector_size, 0, NULL, NULL);
	gpu_check_error(err, "clCreateBuffer() for d_ytemp failed.");
	config->d_k1 = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE, config->vector_size, NULL, &err);
	err |= clEnqueueFillBuffer(config->_cl_queue, config->d_k1, &pattern, element_size, 0, config->vector_size, 0, NULL, NULL);
	gpu_check_error(err, "clCreateBuffer() for d_k1 failed.");
	config->d_k2 = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE, config->vector_size, NULL, &err);
	err |= clEnqueueFillBuffer(config->_cl_queue, config->d_k2, &pattern, element_size, 0, config->vector_size, 0, NULL, NULL);
	gpu_check_error(err, "clCreateBuffer() for d_k2 failed.");
	config->d_k3 = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE, config->vector_size, NULL, &err);
	err |= clEnqueueFillBuffer(config->_cl_queue, config->d_k3, &pattern, element_size, 0, config->vector_size, 0, NULL, NULL);
	gpu_check_error(err, "clCreateBuffer() for d_k3 failed.");
	config->d_k4 = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE, config->vector_size, NULL, &err);
	err |= clEnqueueFillBuffer(config->_cl_queue, config->d_k4, &pattern, element_size, 0, config->vector_size, 0, NULL, NULL);
	gpu_check_error(err, "clCreateBuffer() for d_k4 failed.");
	config->d_t1 = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE, config->vector_size, NULL, &err);
	err |= clEnqueueFillBuffer(config->_cl_queue, config->d_t1, &pattern, element_size, 0, config->vector_size, 0, NULL, NULL);
	gpu_check_error(err, "clCreateBuffer() for d_t1 failed.");

	/* prepare constant memory */
	config->d_c_model = clCreateBuffer(config->_cl_context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, sizeof(config->model), &config->model, &err);
	gpu_check_error(err, "clCreateBuffer() for d_c_model failed.");
	config->d_c_layer = clCreateBuffer(config->_cl_context, CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR, config->layer_size, config->layer, &err);
	gpu_check_error(err, "clCreateBuffer() for d_c_layer failed.");

	/* prepare host memory, this is just for reading the max value from maxdiff kernel */
	config->h_result = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE | CL_MEM_ALLOC_HOST_PTR, element_size, NULL, &err);
	gpu_check_error(err, "clCreateBuffer() for h_result failed.");
	config->pinned_h_result = clEnqueueMapBuffer(config->_cl_queue, config->h_result, CL_TRUE, CL_MAP_READ | CL_MAP_WRITE, 0, element_size, 0, NULL, NULL, &err);
	gpu_check_error(err, "clEnqueueMapBuffer() for pinned_h_result failed.");
	/* host memory for cuboid */
	config->h_cuboid = clCreateBuffer(config->_cl_context, CL_MEM_READ_WRITE | CL_MEM_ALLOC_HOST_PTR, config->vector_size, NULL, &err);
	gpu_check_error(err, "clCreateBuffer() for h_cuboid failed.");
	config->pinned_h_cuboid = clEnqueueMapBuffer(config->_cl_queue, config->h_cuboid, CL_TRUE, CL_MAP_READ | CL_MAP_WRITE, 0, config->vector_size, 0, NULL, NULL, &err);
	gpu_check_error(err, "clEnqueueMapBuffer() for h_cuboid failed.");
	config->h_cuboid_reference = 0;
}

struct timespec gpu_perf_timediff(struct timespec start, struct timespec end)
{
	struct timespec temp;
	if ((end.tv_nsec-start.tv_nsec)<0) {
		temp.tv_sec = end.tv_sec-start.tv_sec-1;
		temp.tv_nsec = 1000000000+end.tv_nsec-start.tv_nsec;
	} else {
		temp.tv_sec = end.tv_sec-start.tv_sec;
		temp.tv_nsec = end.tv_nsec-start.tv_nsec;
	}
	return temp;
}

void* gpu_allocate_cuboid_static(size_t size)
{
	if (current_gpu_config == NULL || !current_gpu_config->gpu_enabled || size != current_gpu_config->vector_size) {
		void* p = malloc(size);
		// printf("malloc %ld bytes %p\n", size, p);
		return p;
	}
	if (current_gpu_config->h_cuboid_reference > 0) {
		fatal("cuboid memory has not been freed before allocation!");
	}
	if (current_gpu_config->h_cuboid_reference < 0) {
		fatal("cuboid memory has not been initialized.");
	}
	// printf("allocating pinned buffer at %p\n", current_gpu_config->pinned_h_cuboid);
	current_gpu_config->h_cuboid_reference++;
	return current_gpu_config->pinned_h_cuboid;
}

void gpu_free_cuboid_static(void* cuboid)
{
	if (current_gpu_config == NULL || !current_gpu_config->gpu_enabled || cuboid != current_gpu_config->pinned_h_cuboid) {
		// printf("freeing %p\n", cuboid);
		free(cuboid);
		return;
	}
	// printf("freeing pinned buffer at %p\n", cuboid);
	if (current_gpu_config->h_cuboid_reference > 0) {
		current_gpu_config->h_cuboid_reference--;
	}
}

void gpu_delete_buffers(gpu_config_t *config)
{
	clReleaseMemObject(config->d_v);
	clReleaseMemObject(config->d_dv);
	clReleaseMemObject(config->d_y);
	clReleaseMemObject(config->d_ytemp);
	clReleaseMemObject(config->d_k1);
	clReleaseMemObject(config->d_k2);
	clReleaseMemObject(config->d_k3);
	clReleaseMemObject(config->d_k4);
	clReleaseMemObject(config->d_t1);
	clReleaseMemObject(config->d_p_cuboid);
	clReleaseMemObject(config->d_c_model);
	clReleaseMemObject(config->d_c_layer);
	clEnqueueUnmapMemObject(config->_cl_queue, config->h_result, config->pinned_h_result, 0, NULL, NULL);
	clEnqueueUnmapMemObject(config->_cl_queue, config->h_cuboid, config->pinned_h_cuboid, 0, NULL, NULL);
	clReleaseMemObject(config->h_result);
	clReleaseMemObject(config->h_cuboid);
}

void gpu_print_array(gpu_config_t *config, cl_mem d_mem, size_t offset, size_t size, char* msg)
{
#ifdef GPU_DEBUG_PRINT
	int i;
	double * buf = (double*)malloc(size * sizeof(double));
	if (msg == NULL) {
		msg = "";
	}
	clEnqueueReadBuffer(config->_cl_queue, d_mem, CL_TRUE, offset * sizeof(double), size * sizeof(double), buf, 0, NULL, NULL);
	for (i = 0; i < size; ++i) {
		printf("%s%.*g\n", msg, 21, buf[i]);
	}
#endif
}

void gpu_init(gpu_config_t *config, grid_model_t *model)
{
	cl_platform_id* platforms;
	cl_device_id* devices;
	cl_uint value_size;
	size_t info_size;
	char* device_name;
	char compiler_options[512] = {0};
	int err;
	current_gpu_config = config;
	if (!config->gpu_enabled) {
#if ENABLE_TIMER > 0
		clock_gettime(CLOCK_MONOTONIC, &config->time_start);
#endif
		return;
	}
	
	gpu_copy_constants(config, model);

	printf("Initializing GPU device...\n");	

	// open platform	
	err = clGetPlatformIDs(0, NULL, &value_size);
	gpu_check_error(err, "Couldn't open OpenCL platform");

	printf("%d OpenCL platforms detected.\n", value_size);
	if (config->platform_id >= value_size) {
		printf("gpu_platform should be in range 0 - %d\n", value_size - 1);
		fatal("Please choose a reasonable gpu_platform value");
	}
	platforms = (cl_platform_id*) malloc(sizeof(cl_platform_id) * value_size);
	clGetPlatformIDs(value_size, platforms, NULL);
	
	
	// open device
	err = clGetDeviceIDs(platforms[config->platform_id], CL_DEVICE_TYPE_GPU, 0, NULL, &value_size);
	gpu_check_error(err, "Couldn't access any GPU devices");
	printf("%d OpenCL devices detected.\n", value_size);
	if (config->device_id >= value_size) {
		printf("gpu_device should be in range 0 - %d\n", value_size - 1);
		fatal("Please choose a reasonable gpu_device value");
	}
	devices = (cl_device_id*) malloc(sizeof(cl_device_id) * value_size);
	clGetDeviceIDs(platforms[config->platform_id], CL_DEVICE_TYPE_GPU, value_size, devices, NULL);
	free(platforms);

	// print device name
	clGetDeviceInfo(devices[config->device_id], CL_DEVICE_NAME, 0, NULL, &info_size);
	device_name = (char*) malloc(info_size);
	clGetDeviceInfo(devices[config->device_id], CL_DEVICE_NAME, info_size, device_name, NULL);
	printf("Selected OpenCL Platform %d Device %d: %s\n", config->platform_id, config->device_id, device_name);
	free(device_name);

	// Create OpenCL context
	config->_cl_context = clCreateContext(NULL, 1, &devices[config->device_id], NULL, NULL, &err);
	gpu_check_error(err, "Couldn't create an OpenCL context");

	// Create a command queue
	config->_cl_queue = clCreateCommandQueue(config->_cl_context, devices[config->device_id], 0, &err);
	gpu_check_error(err, "Couldn't create an OpenCL command queue");

	// Create memory objects
	gpu_create_buffers(config, model);

	// Setup kernel dimensions
	if (model->rows % config->local_work_size[1] || model->cols % config->local_work_size[0])
	{
		fatal("Invalid number of rows or columns");
	}
	config->global_work_size[1] = model->rows;
	config->global_work_size[0] = model->cols;


	// Create OpenCL program
	config->_cl_program = clCreateProgramWithSource(config->_cl_context, 1, (const char**)&config->_cl_kernel_string, &config->_cl_kernel_size, &err);
	gpu_check_error(err, "Couldn't create the OpenCL program");
	int vector_size = config->vector_size / config->element_size;
	sprintf(compiler_options, "-cl-denorms-are-zero -cl-strict-aliasing -cl-fast-relaxed-math "\
			"-DENABLE_SECONDARY_MODEL=%d -DNUMBER_OF_LAYERS=%d -DLOCAL_SIZE_1=(size_t)%d -DLOCAL_SIZE_0=(size_t)%d -DNUMBER_OF_ROWS=(size_t)%d -DNUMBER_OF_COLS=(size_t)%d -DLOCAL_SIZE_1D=(size_t)%d",
			model->config.model_secondary, model->n_layers, (int)config->local_work_size[1], (int)config->local_work_size[0], model->rows, model->cols, (int)(config->local_work_size[0] * config->local_work_size[1]));
	// Build OpenCL program
	printf("compiling kernel with options: %s\n", compiler_options);
	err = clBuildProgram(config->_cl_program, 0, NULL, compiler_options, NULL, NULL);
	if(err < 0) {
		char* build_log;
		// Build failure, print log 
		clGetProgramBuildInfo(config->_cl_program, devices[config->device_id], CL_PROGRAM_BUILD_LOG, 0, NULL, &info_size);
		build_log = (char*) malloc(info_size + 1);
		build_log[info_size] = '\0';
		clGetProgramBuildInfo(config->_cl_program, devices[config->device_id], CL_PROGRAM_BUILD_LOG, info_size + 1, build_log, NULL);
		printf("%s\n", build_log);
		free(build_log);
		fatal("Unabled to build the OpenCL program");
	}
	
	// Create kernel entry point
	config->_cl_kernel_rk4 = clCreateKernel(config->_cl_program, "slope_fn_grid_gpu", &err);
	gpu_check_error(err, "Couldn't create OpenCL kernel slope_fn_grid_gpu()");
	config->_cl_kernel_average = clCreateKernel(config->_cl_program, "rk4_average", &err);
	gpu_check_error(err, "Couldn't create OpenCL kernel rk4_average()");
	config->_cl_kernel_average_with_maxdiff = clCreateKernel(config->_cl_program, "rk4_average_with_maxdiff", &err);
	gpu_check_error(err, "Couldn't create OpenCL kernel rk4_average_with_maxdiff()");
	config->_cl_kernel_max_reduce = clCreateKernel(config->_cl_program, "max_reduce", &err);
	gpu_check_error(err, "Couldn't create OpenCL kernel max_reduce()");


	/* Create kernel arguments */
	err  = clSetKernelArg(config->_cl_kernel_rk4, GRID_CONST_MODEL, sizeof(cl_mem), &config->d_c_model);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_CONST_LAYER, sizeof(cl_mem), &config->d_c_layer);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_IO_V, sizeof(cl_mem), &config->d_v);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_OUT_DV, sizeof(cl_mem), &config->d_dv);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_NL, sizeof(model->n_layers), &model->n_layers);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_NR, sizeof(model->rows), &model->rows);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_NC, sizeof(model->cols), &model->cols);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_LOCALMEM, 4 * (config->local_work_size[0] + 2) * (config->local_work_size[1] + 2) * config->element_size + config->extra_size, NULL); // shared memory for 4 layers
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_IN_CUBOID, sizeof(cl_mem), &config->d_p_cuboid);
	// the 9th argument is h
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_IN_K, sizeof(cl_mem), &config->d_k1);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_IN_Y, sizeof(cl_mem), &config->d_y);
	gpu_check_error(err, "Couldn't setup a OpenCL kernel argument for slope_fn_grid_gpu()");

	err  = clSetKernelArg(config->_cl_kernel_average, AVG_IN_Y, sizeof(cl_mem), &config->d_y);
	err |= clSetKernelArg(config->_cl_kernel_average, AVG_IN_K1, sizeof(cl_mem), &config->d_k1);
	err |= clSetKernelArg(config->_cl_kernel_average, AVG_IN_K2, sizeof(cl_mem), &config->d_k2);
	err |= clSetKernelArg(config->_cl_kernel_average, AVG_IN_K3, sizeof(cl_mem), &config->d_k3);
	err |= clSetKernelArg(config->_cl_kernel_average, AVG_IN_K4, sizeof(cl_mem), &config->d_k4);
	// the 5th argument is h
	err |= clSetKernelArg(config->_cl_kernel_average, AVG_OUT_YOUT, sizeof(cl_mem), &config->d_dv);
	err |= clSetKernelArg(config->_cl_kernel_average, AVG_N, sizeof(vector_size), &vector_size);
	gpu_check_error(err, "Couldn't setup a OpenCL kernel argument for rk4_average()");
	err  = clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_IN_Y, sizeof(cl_mem), &config->d_y);
	err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_IN_K1, sizeof(cl_mem), &config->d_k1);
	err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_IN_K2, sizeof(cl_mem), &config->d_k2);
	err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_IN_K3, sizeof(cl_mem), &config->d_k3);
	err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_IN_K4, sizeof(cl_mem), &config->d_k4);
	// the 5th argument is h
	err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_OUT_YOUT, sizeof(cl_mem), &config->d_dv);
	err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_N, sizeof(vector_size), &vector_size);
	err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_IN_YTEMP, sizeof(cl_mem), &config->d_ytemp);
	err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_LOCALMEM, (config->local_work_size[0]) * (config->local_work_size[1]) * config->element_size, NULL);
	gpu_check_error(err, "Couldn't setup a OpenCL kernel argument for rk4_average()");
	int remained_items = (config->global_work_size[0] * config->global_work_size[1]) / (config->local_work_size[0] * config->local_work_size[1]);
	err  = clSetKernelArg(config->_cl_kernel_max_reduce, MAX_IO_Y, sizeof(cl_mem), &config->d_dv);
	err |= clSetKernelArg(config->_cl_kernel_max_reduce, MAX_N, sizeof(remained_items), &remained_items);
	err |= clSetKernelArg(config->_cl_kernel_max_reduce, MAX_LOCALMEM, (config->local_work_size[0]) * (config->local_work_size[1]) * config->element_size, NULL);
	gpu_check_error(err, "Couldn't setup a OpenCL kernel argument for max_reduce()");
	
	printf("OpenCL initialized.\n");
	config->cpu_dma = fopen("/dev/cpu_dma_latency", "w");
	if (config->cpu_dma != NULL) {
		int32_t target = 0;
		fwrite(&target, sizeof(target), 1, config->cpu_dma);
		printf("CPU C-states disabled.\n");
	}
	else {
		printf("Can't disable C-states. Do you have write permission to /dev/cpu_dma_latency?\n");
	}
	free(devices);
#if ENABLE_TIMER > 0
	clock_gettime(CLOCK_MONOTONIC, &config->time_start);
#endif
}

void gpu_destroy(gpu_config_t *config)
{
#if ENABLE_TIMER > 0
	clock_gettime(CLOCK_MONOTONIC, &config->time_end);
	struct timespec time_diff = gpu_perf_timediff(config->time_start, config->time_end);
#endif
	if (!config->gpu_enabled) {
#if ENABLE_TIMER > 0
		printf("CPU Time: %ld.%09lds\n", time_diff.tv_sec, time_diff.tv_nsec);
#endif
		return;
	}
#if ENABLE_TIMER > 0
	printf("GPU Time: %ld.%09lds\n", time_diff.tv_sec, time_diff.tv_nsec);
#endif
	free(config->layer);
	gpu_delete_buffers(config);

	// TODO
	clReleaseKernel(config->_cl_kernel_rk4);
	clReleaseKernel(config->_cl_kernel_average);
	clReleaseKernel(config->_cl_kernel_average_with_maxdiff);
	clReleaseKernel(config->_cl_kernel_max_reduce);

	clReleaseCommandQueue(config->_cl_queue);
	clReleaseProgram(config->_cl_program);
	clReleaseContext(config->_cl_context);
	current_gpu_config = NULL; // prevents pinned memory allocation
	puts("OpenCL environment has been cleaned up.\n");
	if (config->cpu_dma != NULL) {
		fclose(config->cpu_dma);
	}
}

/* 
 * 4th order Runge Kutta solver	with adaptive step sizing.
 * It integrates and solves the ODE dy + cy = p between
 * t and t+h. It returns the correct step size to be used 
 * next time. slope function f is the call back used to 
 * evaluate the derivative at each point
 */
#define RK4_SAFETY		0.95
#define RK4_MAXUP		5.0
#define RK4_MAXDOWN		10.0
#define RK4_PRECISION	0.01
double rk4_gpu(gpu_config_t *config, void *model, double *y, void *p, int n, double *h, double *yout)
{
	int i;
	double max, new_h = (*h);
	// double * input;
	// double * output;

	// input = dvector(n);
	// output = dvector(n);

	size_t buffer_size = config->vector_size;
	// printf("buffer_size = %zu, n = %d\n", buffer_size, n);
	/* copy p->cuboid to device */
	clEnqueueWriteBuffer(config->_cl_queue, config->d_p_cuboid, CL_FALSE, 0, buffer_size, ((grid_model_vector_t*)p)->cuboid[0][0], 0, NULL, NULL);
	/* copy y to device */
	clEnqueueWriteBuffer(config->_cl_queue, config->d_y, CL_FALSE, 0, buffer_size, y, 0, NULL, NULL);

	/* evaluate the slope k1 at the beginning */
	// slope_fn_grid_gpu_kernel(config, model, y, p, k1);
	DEBUG_Flush(config->_cl_queue);
	gpu_print_array(config, config->d_y, DEBUG_POS, 1, "y:\t");
	gpu_print_array(config, config->d_p_cuboid, DEBUG_POS, 1, "cuboid:\t");
	// clEnqueueReadBuffer(config->_cl_queue, config->d_y, CL_TRUE, 0, buffer_size, input, 0, NULL, NULL);
	slope_fn_grid_gpu_kernel(config, model, &config->d_y, p, &config->d_k1);
	// slope_fn_grid_gpu(config, model, input, p, output);
	// clEnqueueWriteBuffer(config->_cl_queue, config->d_k1, CL_TRUE, 0, buffer_size, output, 0, NULL, NULL);

	gpu_print_array(config, config->d_k1, DEBUG_POS, 1, "k1:\t");
	/* try until accuracy is achieved	*/
	do {
		(*h) = new_h;
		DEBUG_Flush(config->_cl_queue);
		/* try RK4 once with normal step size	*/
		// rk4_core_gpu_kernel(config, model, y, k1, p, n, (*h), ytemp, NULL, 0);
		rk4_core_gpu_kernel(config, model, &config->d_y, &config->d_k1, p, n, (*h), &config->d_ytemp, NULL, 0);
		gpu_print_array(config, config->d_ytemp, DEBUG_POS, 1, "ytemp:\t");
		DEBUG_Flush(config->_cl_queue);
		/* repeat it with two half-steps	*/
		// rk4_core_gpu_kernel(config, model, y, k1, p, n, (*h)/2.0, t1, NULL, 0);
		rk4_core_gpu_kernel(config, model, &config->d_y, &config->d_k1, p, n, (*h)/2.0, &config->d_t1, NULL, 0);
		gpu_print_array(config, config->d_t1, DEBUG_POS, 1, "t1:\t");
		DEBUG_Flush(config->_cl_queue);
		/* y after 1st half-step is in t1. re-evaluate k1 for this	*/
		// slope_fn_grid_gpu_kernel(config, model, t1, p, k1);
		// clEnqueueReadBuffer(config->_cl_queue, config->d_t1, CL_TRUE, 0, buffer_size, input, 0, NULL, NULL);
		// slope_fn_grid_gpu(config, model, input, p, output);
		// clEnqueueWriteBuffer(config->_cl_queue, config->d_k1, CL_TRUE, 0, buffer_size, output, 0, NULL, NULL);
		slope_fn_grid_gpu_kernel(config, model, &config->d_t1, p, &config->d_k1);
		gpu_print_array(config, config->d_k1, DEBUG_POS, 1, "k1:\t");
		DEBUG_Flush(config->_cl_queue);
		/* get output of the second half-step in t2	*/	
		// rk4_core_gpu_kernel(config, model, t1, k1, p, n, (*h)/2.0, t2, ytemp, 1);
		rk4_core_gpu_kernel(config, model, &config->d_t1, &config->d_k1, p, n, (*h)/2.0, &config->d_dv, &config->d_ytemp, 1);
		gpu_print_array(config, config->d_dv, 0, 1, "dv:\t");
		DEBUG_Flush(config->_cl_queue);
		/* find the max diff between these two results:
		 * use t1 to store the diff
		 */
		/*
		for(i=0; i < n; i++)
			t1[i] = fabs(ytemp[i] - t2[i]);
		max = t1[0];
		for(i=1; i < n; i++)
			if (max < t1[i])
				max = t1[i];
		*/
		clEnqueueReadBuffer(config->_cl_queue, config->d_dv, CL_TRUE, 0, config->element_size, config->pinned_h_result, 0, NULL, NULL);
		max = ((double*)config->pinned_h_result)[0]; // TODO: support single precision

		/* 
		 * compute the correct step size: see equation 
		 * 16.2.10  in chapter 16 of "Numerical Recipes
		 * in C"
		 */
		/* accuracy OK. increase step size	*/
		if (max <= RK4_PRECISION) {
			new_h = RK4_SAFETY * (*h) * pow(fabs(RK4_PRECISION/max), 0.2);
			if (new_h > RK4_MAXUP * (*h))
				new_h = RK4_MAXUP * (*h);
		/* inaccuracy error. decrease step size	and compute again */
		} else {
			new_h = RK4_SAFETY * (*h) * pow(fabs(RK4_PRECISION/max), 0.25);
			if (new_h < (*h) / RK4_MAXDOWN)
				new_h = (*h) / RK4_MAXDOWN;
		}

	} while (new_h < (*h));

	/* commit ytemp to yout	*/
	// copy_dvector(yout, ytemp, n);
	clEnqueueReadBuffer(config->_cl_queue, config->d_ytemp, CL_TRUE, 0, buffer_size, yout, 0, NULL, NULL);

	/* return the step-size	*/
	// free_dvector(input);
	// free_dvector(output);
	return new_h;
}

/* core of the 4th order Runge-Kutta method, where the Euler step
 * (y(n+1) = y(n) + h * k1 where k1 = dydx(n)) is provided as an input.
 * to evaluate dydx at different points, a call back function f (slope
 * function) is also passed as a parameter. Given values for y, and k1, 
 * this function advances the solution over an interval h, and returns
 * the solution in yout. For details, see the discussion in "Numerical 
 * Recipes in C", Chapter 16, from 
 * http://www.nrbook.com/a/bookcpdf/c16-1.pdf
 */
void rk4_core_gpu(gpu_config_t *config, void *model, double *y, double *k1, void *p, int n, double h, double *yout)
{
	int i;
	double *t, *k2, *k3, *k4;
	double h_real;
	k2 = dvector(n);
	k3 = dvector(n);
	k4 = dvector(n);
	t = dvector(n);

	/* k2 is the slope at the trial midpoint (t) found using 
	 * slope k1 (which is at the starting point).
	 */
	/* t = y + h/2 * k1 (t = y; t += h/2 * k1) */
	for(i=0; i < n; i++)
		t[i] = y[i] + h/2.0 * k1[i];
	
	/* k2 = slope at t */
	slope_fn_grid_gpu(config, model, t, p, k2);

	/* k3 is the slope at the trial midpoint (t) found using
	 * slope k2 found above.
	 */
	/* t =  y + h/2 * k2 (t = y; t += h/2 * k2) */
	for(i=0; i < n; i++)
		t[i] = y[i] + h/2.0 * k2[i];
	/* k3 = slope at t */
	slope_fn_grid_gpu(config, model, t, p, k3);

	/* k4 is the slope at trial endpoint (t) found using
	 * slope k3 found above.
	 */
	/* t =  y + h * k3 (t = y; t += h * k3) */
	for(i=0; i < n; i++)
		t[i] = y[i] + h * k3[i];

	/* k4 = slope at t */
	slope_fn_grid_gpu(config, model, t, p, k4);
	/*
	clEnqueueWriteBuffer(config->_cl_queue, config->d_y, CL_FALSE, 0, config->vector_size, y, 0, NULL, NULL);
	clEnqueueWriteBuffer(config->_cl_queue, config->d_k1, CL_FALSE, 0, config->vector_size, k1, 0, NULL, NULL);
	clEnqueueWriteBuffer(config->_cl_queue, config->d_k2, CL_FALSE, 0, config->vector_size, k2, 0, NULL, NULL);
	clEnqueueWriteBuffer(config->_cl_queue, config->d_k3, CL_FALSE, 0, config->vector_size, k3, 0, NULL, NULL);
	clEnqueueWriteBuffer(config->_cl_queue, config->d_k4, CL_FALSE, 0, config->vector_size, k4, 0, NULL, NULL);
	clSetKernelArg(config->_cl_kernel_average, 5, sizeof(h), &h);
	clEnqueueNDRangeKernel(config->_cl_queue, config->_cl_kernel_average, 2, NULL, config->global_work_size, config->local_work_size, 0, NULL, NULL);
	clEnqueueReadBuffer(config->_cl_queue, config->d_dv, CL_TRUE, 0, config->vector_size, yout, 0, NULL, NULL);
	*/

	/* yout = y + h*(k1/6 + k2/3 + k3/3 + k4/6)	*/
	for (i =0; i < n; i++) 
		yout[i] = y[i] + h * (k1[i] + 2*k2[i] + 2*k3[i] + k4[i])/6.0;

	free_dvector(k2);
	free_dvector(k3);
	free_dvector(k4);
	free_dvector(t);
}

void rk4_core_gpu_kernel(gpu_config_t *config, void *model, cl_mem *d_y, cl_mem *d_k1, void *p, int n, double h, cl_mem *d_yout, cl_mem *d_ytemp, int do_maxdiff)
{
	int i;
	double h_real;
	int err;
	/* k2 is the slope at the trial midpoint (t) found using
	 * slope k1 (which is at the starting point).
	 */
	/* t = y + h/2 * k1 (t = y; t += h/2 * k1) */
	// for(i=0; i < n; i++)
	//	t[i] = y[i] + h/2.0 * k1[i];

	/* k2 = slope at t */
	// slope_fn_grid_gpu_kernel(config, model, t, p, k2);
	h_real = h / 2.0;
	/* inputs */
	err = clSetKernelArg(config->_cl_kernel_rk4, GRID_IN_Y, sizeof(cl_mem), d_y);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_H, sizeof(h_real), &h_real);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_IN_K, sizeof(cl_mem), d_k1);
	/* output to d_k2 */
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_OUT_DV, sizeof(cl_mem), &config->d_k2);
	/* IO buffer */
	err = clSetKernelArg(config->_cl_kernel_rk4, GRID_IO_V, sizeof(cl_mem), d_yout);
	gpu_check_error(err, "Couldn't setup a OpenCL kernel argument in rk4_core_gpu_kernel()");
	err = clEnqueueNDRangeKernel(config->_cl_queue, config->_cl_kernel_rk4, 2, NULL, config->global_work_size, config->local_work_size, 0, NULL, NULL);
	gpu_check_error(err, "Cannot launch kernel rk4_core_gpu_kernel()!");
	gpu_print_array(config, config->d_k2, DEBUG_POS, 1, "core:k2:\t");
	/* k3 is the slope at the trial midpoint (t) found using
	 * slope k2 found above.
	 */
	/* t =  y + h/2 * k2 (t = y; t += h/2 * k2) */
	// for(i=0; i < n; i++)
	//	t[i] = y[i] + h/2.0 * k2[i];

	/* k3 = slope at t */
	// slope_fn_grid_gpu_kernel(config, model, t, p, k3);
	/* h is not changed, d_k2 is the output of the previous kernel */
	err = clSetKernelArg(config->_cl_kernel_rk4, GRID_IN_K, sizeof(cl_mem), &config->d_k2);
	// output to d_k3
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_OUT_DV, sizeof(cl_mem), &config->d_k3);
	gpu_check_error(err, "Couldn't setup a OpenCL kernel argument in rk4_core_gpu_kernel()");
	err = clEnqueueNDRangeKernel(config->_cl_queue, config->_cl_kernel_rk4, 2, NULL, config->global_work_size, config->local_work_size, 0, NULL, NULL);
	gpu_check_error(err, "Cannot launch kernel rk4_core_gpu_kernel()!");
	gpu_print_array(config, config->d_k3, DEBUG_POS, 1, "core:k3:\t");
	/* k4 is the slope at trial endpoint (t) found using
	 * slope k3 found above.
	 */
	/* t =  y + h * k3 (t = y; t += h * k3) */
	// for(i=0; i < n; i++)
	//	t[i] = y[i] + h * k3[i];

	/* k4 = slope at t */
	// slope_fn_grid_gpu_kernel(config, model, t, p, k4);
	/* inputs */
	h_real = h;
	err = clSetKernelArg(config->_cl_kernel_rk4, GRID_H, sizeof(h_real), &h_real);
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_IN_K, sizeof(cl_mem), &config->d_k3);
	/* output to d_k4 */
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_OUT_DV, sizeof(cl_mem), &config->d_k4);
	gpu_check_error(err, "Couldn't setup a OpenCL kernel argument in rk4_core_gpu_kernel()");
	err = clEnqueueNDRangeKernel(config->_cl_queue, config->_cl_kernel_rk4, 2, NULL, config->global_work_size, config->local_work_size, 0, NULL, NULL);
	gpu_check_error(err, "Cannot launch kernel rk4_core_gpu_kernel()!");
	gpu_print_array(config, config->d_k4, DEBUG_POS, 1, "core:k4:\t");
	/* yout = y + h*(k1/6 + k2/3 + k3/3 + k4/6)	*/
	// for (i =0; i < n; i++)
	//	yout[i] = y[i] + h * (k1[i] + 2*k2[i] + 2*k3[i] + k4[i])/6.0;
	if (do_maxdiff) {
		err = clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_IN_Y, sizeof(cl_mem), d_y);
		err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_IN_K1, sizeof(cl_mem), d_k1);
		err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_H, sizeof(h_real), &h_real);
		err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_OUT_YOUT, sizeof(cl_mem), d_yout);
		err |= clSetKernelArg(config->_cl_kernel_average_with_maxdiff, AVG_IN_YTEMP, sizeof(cl_mem), d_ytemp);
		gpu_check_error(err, "Couldn't setup a OpenCL kernel argument in rk4_average_with_maxdiff()");
		/* first phase reduction, results to be saved to yout */
		size_t avg_kernel_global_size = config->global_work_size[0] * config->global_work_size[1];
		size_t avg_kernel_local_size = config->local_work_size[0] * config->local_work_size[1];
		err = clEnqueueNDRangeKernel(config->_cl_queue, config->_cl_kernel_average_with_maxdiff, 1, NULL, &avg_kernel_global_size, &avg_kernel_local_size, 0, NULL, NULL);
		gpu_check_error(err, "Cannot launch kernel rk4_average_with_maxdiff()!");
		/* second phase reduction, with 1 block only, read inputs from yout */
		err = clSetKernelArg(config->_cl_kernel_max_reduce, MAX_IO_Y, sizeof(cl_mem), d_yout);
		gpu_check_error(err, "Couldn't setup a OpenCL kernel argument in rk4_average_with_maxdiff()");
		err = clEnqueueNDRangeKernel(config->_cl_queue, config->_cl_kernel_max_reduce, 1, NULL, &avg_kernel_local_size, &avg_kernel_local_size, 0, NULL, NULL);
		gpu_check_error(err, "Cannot launch kernel max_reduce()!");
	}
	else {
		err = clSetKernelArg(config->_cl_kernel_average, AVG_IN_Y, sizeof(cl_mem), d_y);
		err |= clSetKernelArg(config->_cl_kernel_average, AVG_IN_K1, sizeof(cl_mem), d_k1);
		err |= clSetKernelArg(config->_cl_kernel_average, AVG_H, sizeof(h_real), &h_real);
		err |= clSetKernelArg(config->_cl_kernel_average, AVG_OUT_YOUT, sizeof(cl_mem), d_yout);
		gpu_print_array(config, *d_y, DEBUG_POS, 1, "core:y:\t");
		gpu_print_array(config, *d_k1, DEBUG_POS, 1, "core:k1:\t");
		gpu_print_array(config, config->d_k2, DEBUG_POS, 1, "core:k2:\t");
		gpu_print_array(config, config->d_k3, DEBUG_POS, 1, "core:k3:\t");
		gpu_print_array(config, config->d_k4, DEBUG_POS, 1, "core:k4:\t");
		gpu_check_error(err, "Couldn't setup a OpenCL kernel argument in rk4_average()");
		size_t avg_kernel_global_size = config->global_work_size[0] * config->global_work_size[1];
		size_t avg_kernel_local_size = config->local_work_size[0] * config->local_work_size[1];
		err = clEnqueueNDRangeKernel(config->_cl_queue, config->_cl_kernel_average, 1, NULL, &avg_kernel_global_size, &avg_kernel_local_size, 0, NULL, NULL);
		gpu_check_error(err, "Cannot launch kernel rk4_average()!");
		gpu_print_array(config, *d_yout, DEBUG_POS, 1, "core:yout:\t");
	}
}

void slope_fn_grid_gpu_kernel(gpu_config_t *config, grid_model_t *model, cl_mem *d_v, grid_model_vector_t *p, cl_mem *d_dv)
{
	int err;

	/* disable endpoint calculation */
	double h = 0.0;
	err = clSetKernelArg(config->_cl_kernel_rk4, GRID_H, sizeof(double), &h);
	/* input from d_v */
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_IO_V, sizeof(cl_mem), d_v);
	/* output to d_dv */
	err |= clSetKernelArg(config->_cl_kernel_rk4, GRID_OUT_DV, sizeof(cl_mem), d_dv);
	gpu_check_error(err, "Couldn't setup a OpenCL kernel argument in rk4_core_gpu_kernel()");
	err = clEnqueueNDRangeKernel(config->_cl_queue, config->_cl_kernel_rk4, 2, NULL, config->global_work_size, config->local_work_size, 0, NULL, NULL);
	gpu_check_error(err, "Cannot launch kernel slope_fn_grid_gpu()!");
	// slope_fn_grid_gpu(config, model, v, p, dv);
}

/* function to access a 1-d array as a 3-d matrix	*/
#define A3D(array,n,i,j,nl,nr,nc)		(array[(n)*(nr)*(nc) + (i)*(nc) + (j)])
/* macros for calculating currents(power values)	*/
/* current(power) from the next cell north. zero if on northern boundary	*/
# define NP(l,v,n,i,j,nl,nr,nc)		((i > 0) ? ((A3D(v,n,i-1,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].ry) : 0.0)
/* current(power) from the next cell south. zero if on southern boundary	*/
# define SP(l,v,n,i,j,nl,nr,nc)		((i < nr-1) ? ((A3D(v,n,i+1,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].ry) : 0.0)
/* current(power) from the next cell east. zero if on eastern boundary	*/
# define EP(l,v,n,i,j,nl,nr,nc)		((j < nc-1) ? ((A3D(v,n,i,j+1,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].rx) : 0.0)
/* current(power) from the next cell west. zero if on western boundary	*/
# define WP(l,v,n,i,j,nl,nr,nc)		((j > 0) ? ((A3D(v,n,i,j-1,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].rx) : 0.0)
/* current(power) from the next cell below. zero if on bottom face		*/
# define BP(l,v,n,i,j,nl,nr,nc)		((n < nl-1) ? ((A3D(v,n+1,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].rz) : 0.0)
/* current(power) from the next cell above. zero if on top face			*/
# define AP(l,v,n,i,j,nl,nr,nc)		((n > 0) ? ((A3D(v,n-1,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n-1].rz) : 0.0)

/* compute the slope vector for the grid cells. the transient
 * equation is CdV + sum{(T - Ti)/Ri} = P 
 * so, slope = dV = [P + sum{(Ti-T)/Ri}]/C
 */
void slope_fn_grid_gpu(gpu_config_t *config, grid_model_t *model, double *v, grid_model_vector_t *p, double *dv)
{
	int n, i, j;
	/* sum of the currents(power values)	*/
	double psum;
	
	/* shortcuts for cell width(cw) and cell height(ch)	*/
	double cw = model->width / model->cols;
	double ch = model->height / model->rows;

	/* shortcuts	*/
	thermal_config_t *c = &model->config;
	layer_t *l = model->layers;
	int nl = model->n_layers;
	int nr = model->rows;
	int nc = model->cols;
	int spidx, hsidx, metalidx, c4idx, subidx, solderidx, pcbidx;
	int model_secondary = model->config.model_secondary;
	
	/* pointer to the starting address of the extra nodes	*/
	double *x = v + nl*nr*nc;
	
	if (!model->config.model_secondary) {
		spidx = nl - DEFAULT_PACK_LAYERS + LAYER_SP;
		hsidx = nl - DEFAULT_PACK_LAYERS + LAYER_SINK;
	} else {
		spidx = nl - DEFAULT_PACK_LAYERS - SEC_PACK_LAYERS + LAYER_SP;
		hsidx = nl - DEFAULT_PACK_LAYERS - SEC_PACK_LAYERS + LAYER_SINK;
		metalidx = nl - DEFAULT_PACK_LAYERS - SEC_PACK_LAYERS - SEC_CHIP_LAYERS + LAYER_METAL;
		c4idx = nl - DEFAULT_PACK_LAYERS - SEC_PACK_LAYERS - SEC_CHIP_LAYERS + LAYER_C4;
		subidx = nl - SEC_PACK_LAYERS + LAYER_SUB;
		solderidx = nl - SEC_PACK_LAYERS + LAYER_SOLDER;
		pcbidx = nl - SEC_PACK_LAYERS + LAYER_PCB;		
	}
	
	/* for each grid cell	*/
	for(n=0; n < nl; n++)
		for(i=0; i < nr; i++)
			for(j=0; j < nc; j++) {
				if (n==LAYER_SI && model_secondary) { //top silicon layer
					psum = NP(l,v,n,i,j,nl,nr,nc) + SP(l,v,n,i,j,nl,nr,nc) + 
					   EP(l,v,n,i,j,nl,nr,nc) + WP(l,v,n,i,j,nl,nr,nc) + 
					   ((A3D(v,metalidx,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[metalidx].rz) +
					   ((A3D(v,n+1,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].rz);
				} else if (n==spidx && model_secondary) { //spreader layer
					psum = NP(l,v,n,i,j,nl,nr,nc) + SP(l,v,n,i,j,nl,nr,nc) + 
					   EP(l,v,n,i,j,nl,nr,nc) + WP(l,v,n,i,j,nl,nr,nc) + 
					   ((A3D(v,metalidx-1,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[metalidx-1].rz) +
					   ((A3D(v,hsidx,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].rz);
				} else if (n==metalidx && model_secondary) { //metal layer
					psum = NP(l,v,n,i,j,nl,nr,nc) + SP(l,v,n,i,j,nl,nr,nc) + 
					   EP(l,v,n,i,j,nl,nr,nc) + WP(l,v,n,i,j,nl,nr,nc) + 
					   ((A3D(v,c4idx,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[c4idx].rz) +
					   ((A3D(v,LAYER_SI,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].rz);
				} else if (n==metalidx-1 && model_secondary) { // TIM layer
					psum = NP(l,v,n,i,j,nl,nr,nc) + SP(l,v,n,i,j,nl,nr,nc) + 
					   EP(l,v,n,i,j,nl,nr,nc) + WP(l,v,n,i,j,nl,nr,nc) + 
					   ((A3D(v,metalidx-2,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[metalidx-2].rz) +
					   ((A3D(v,spidx,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].rz);
				} else if (n==c4idx && model_secondary) { //C4 layer
					psum = NP(l,v,n,i,j,nl,nr,nc) + SP(l,v,n,i,j,nl,nr,nc) + 
					   EP(l,v,n,i,j,nl,nr,nc) + WP(l,v,n,i,j,nl,nr,nc) + 
					   ((A3D(v,subidx,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[subidx].rz) +
					   ((A3D(v,metalidx,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].rz);
				} else if (n==subidx && model_secondary) { //Substrate layer
					psum = NP(l,v,n,i,j,nl,nr,nc) + SP(l,v,n,i,j,nl,nr,nc) + 
					   EP(l,v,n,i,j,nl,nr,nc) + WP(l,v,n,i,j,nl,nr,nc) + 
					   ((A3D(v,solderidx,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[solderidx].rz) +
					   ((A3D(v,c4idx,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].rz);
				} else if (n==pcbidx && model_secondary) { //PCB layer
					psum = NP(l,v,n,i,j,nl,nr,nc) + SP(l,v,n,i,j,nl,nr,nc) + 
					   EP(l,v,n,i,j,nl,nr,nc) + WP(l,v,n,i,j,nl,nr,nc) + 
					   ((A3D(v,solderidx,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[n].rz);
				} else if (n==hsidx && model_secondary) { // heatsink layer
					psum = NP(l,v,n,i,j,nl,nr,nc) + SP(l,v,n,i,j,nl,nr,nc) + 
					   EP(l,v,n,i,j,nl,nr,nc) + WP(l,v,n,i,j,nl,nr,nc) + 
					   ((A3D(v,spidx,i,j,nl,nr,nc)-A3D(v,n,i,j,nl,nr,nc))/l[spidx].rz);
				} else {
					/* sum the currents(power values) to cells north, south, 
				 	* east, west, above and below
				 	*/
					psum = NP(l,v,n,i,j,nl,nr,nc) + SP(l,v,n,i,j,nl,nr,nc) + 
					   EP(l,v,n,i,j,nl,nr,nc) + WP(l,v,n,i,j,nl,nr,nc) + 
					   AP(l,v,n,i,j,nl,nr,nc) + BP(l,v,n,i,j,nl,nr,nc);
				}

				/* spreader core is connected to its periphery	*/
				if (n == spidx) {
					/* northern boundary - edge cell has half the ry	*/
					if (i == 0)
						psum += (x[SP_N] - A3D(v,n,i,j,nl,nr,nc))/(l[n].ry/2.0 + nc*model->pack.r_sp1_y); 
					/* southern boundary - edge cell has half the ry	*/
					if (i == nr-1)
						psum += (x[SP_S] - A3D(v,n,i,j,nl,nr,nc))/(l[n].ry/2.0 + nc*model->pack.r_sp1_y); 
					/* eastern boundary	 - edge cell has half the rx	*/
					if (j == nc-1)
						psum += (x[SP_E] - A3D(v,n,i,j,nl,nr,nc))/(l[n].rx/2.0 + nr*model->pack.r_sp1_x); 
					/* western boundary	 - edge cell has half the rx	*/
					if (j == 0)
						psum += (x[SP_W] - A3D(v,n,i,j,nl,nr,nc))/(l[n].rx/2.0 + nr*model->pack.r_sp1_x); 
				/* heatsink core is connected to its inner periphery and ambient	*/
				} else if (n == hsidx) {
					/* all nodes are connected to the ambient	*/
					psum += (c->ambient - A3D(v,n,i,j,nl,nr,nc))/l[n].rz;
					/* northern boundary - edge cell has half the ry	*/
					if (i == 0)
						psum += (x[SINK_C_N] - A3D(v,n,i,j,nl,nr,nc))/(l[n].ry/2.0 + nc*model->pack.r_hs1_y); 
					/* southern boundary - edge cell has half the ry	*/
					if (i == nr-1)
						psum += (x[SINK_C_S] - A3D(v,n,i,j,nl,nr,nc))/(l[n].ry/2.0 + nc*model->pack.r_hs1_y); 
					/* eastern boundary	 - edge cell has half the rx	*/
					if (j == nc-1)
						psum += (x[SINK_C_E] - A3D(v,n,i,j,nl,nr,nc))/(l[n].rx/2.0 + nr*model->pack.r_hs1_x); 
					/* western boundary	 - edge cell has half the rx	*/
					if (j == 0)
						psum += (x[SINK_C_W] - A3D(v,n,i,j,nl,nr,nc))/(l[n].rx/2.0 + nr*model->pack.r_hs1_x); 
				}	else if (n == pcbidx && model->config.model_secondary) {
					/* all nodes are connected to the ambient	*/
					psum += (c->ambient - A3D(v,n,i,j,nl,nr,nc))/(model->config.r_convec_sec * 
								   (model->config.s_pcb * model->config.s_pcb) / (cw * ch));
					/* northern boundary - edge cell has half the ry	*/
					if (i == 0)
						psum += (x[PCB_C_N] - A3D(v,n,i,j,nl,nr,nc))/(l[n].ry/2.0 + nc*model->pack.r_pcb1_y); 
					/* southern boundary - edge cell has half the ry	*/
					if (i == nr-1)
						psum += (x[PCB_C_S] - A3D(v,n,i,j,nl,nr,nc))/(l[n].ry/2.0 + nc*model->pack.r_pcb1_y); 
					/* eastern boundary	 - edge cell has half the rx	*/
					if (j == nc-1)
						psum += (x[PCB_C_E] - A3D(v,n,i,j,nl,nr,nc))/(l[n].rx/2.0 + nr*model->pack.r_pcb1_x); 
					/* western boundary	 - edge cell has half the rx	*/
					if (j == 0)
						psum += (x[PCB_C_W] - A3D(v,n,i,j,nl,nr,nc))/(l[n].rx/2.0 + nr*model->pack.r_pcb1_x); 
				}	else if (n == subidx && model->config.model_secondary) {
					/* northern boundary - edge cell has half the ry	*/
					if (i == 0)
						psum += (x[SUB_N] - A3D(v,n,i,j,nl,nr,nc))/(l[n].ry/2.0 + nc*model->pack.r_sub1_y); 
					/* southern boundary - edge cell has half the ry	*/
					if (i == nr-1)
						psum += (x[SUB_S] - A3D(v,n,i,j,nl,nr,nc))/(l[n].ry/2.0 + nc*model->pack.r_sub1_y); 
					/* eastern boundary	 - edge cell has half the rx	*/
					if (j == nc-1)
						psum += (x[SUB_E] - A3D(v,n,i,j,nl,nr,nc))/(l[n].rx/2.0 + nr*model->pack.r_sub1_x); 
					/* western boundary	 - edge cell has half the rx	*/
					if (j == 0)
						psum += (x[SUB_W] - A3D(v,n,i,j,nl,nr,nc))/(l[n].rx/2.0 + nr*model->pack.r_sub1_x); 
				}	else if (n == solderidx && model->config.model_secondary) {
					/* northern boundary - edge cell has half the ry	*/
					if (i == 0)
						psum += (x[SOLDER_N] - A3D(v,n,i,j,nl,nr,nc))/(l[n].ry/2.0 + nc*model->pack.r_solder1_y); 
					/* southern boundary - edge cell has half the ry	*/
					if (i == nr-1)
						psum += (x[SOLDER_S] - A3D(v,n,i,j,nl,nr,nc))/(l[n].ry/2.0 + nc*model->pack.r_solder1_y); 
					/* eastern boundary	 - edge cell has half the rx	*/
					if (j == nc-1)
						psum += (x[SOLDER_E] - A3D(v,n,i,j,nl,nr,nc))/(l[n].rx/2.0 + nr*model->pack.r_solder1_x); 
					/* western boundary	 - edge cell has half the rx	*/
					if (j == 0)
						psum += (x[SOLDER_W] - A3D(v,n,i,j,nl,nr,nc))/(l[n].rx/2.0 + nr*model->pack.r_solder1_x); 
				}

				/* update the current cell's temperature	*/	   
				A3D(dv,n,i,j,nl,nr,nc) = (p->cuboid[n][i][j] + psum) / l[n].c;
			}
	// slope_fn_pack_gpu_kernel(config, model, v, p, dv);
	slope_fn_pack_gpu(config, model, v, p, dv);
}

/* compute the slope vector for the package nodes	*/
void slope_fn_pack_gpu_kernel(gpu_config_t *config, grid_model_t *model, double *v, grid_model_vector_t *p, double *dv)
{
	int err;
	unsigned int data_offset = (model->n_layers * model->rows * model->cols) * config->element_size;
	size_t buffer_size = config->vector_size;
	// prepare a pinned buffer
	config->h_v = clCreateBuffer(config->_cl_context, CL_MEM_READ_ONLY | CL_MEM_USE_HOST_PTR, buffer_size, v, &err);
	gpu_check_error(err, "clCreateBuffer() for h_v failed.");

	// copy pinned *v to device
	config->pinned_h_v = clEnqueueMapBuffer(config->_cl_queue, config->h_v, CL_TRUE, CL_MAP_READ, 0, buffer_size, 0, NULL, NULL, &err);
	gpu_check_error(err, "clEnqueueMapBuffer() for pinned_h_v failed.");
	clEnqueueWriteBuffer(config->_cl_queue, config->d_v, CL_FALSE, 0, buffer_size, config->pinned_h_v, 0, NULL, NULL);
	clEnqueueUnmapMemObject(config->_cl_queue, config->h_v, config->pinned_h_v, 0, NULL, NULL);

	// launch kernel
	err = clEnqueueNDRangeKernel(config->_cl_queue, config->_cl_kernel_rk4, 2, NULL, config->global_work_size, config->local_work_size, 0, NULL, NULL);
	gpu_check_error(err, "Cannot launch kernel!");

	// copy result back
	config->h_result = clCreateBuffer(config->_cl_context, CL_MEM_WRITE_ONLY | CL_MEM_USE_HOST_PTR, buffer_size, dv, &err);
	gpu_check_error(err, "clCreateBuffer() for h_result failed.");
	config->pinned_h_result = clEnqueueMapBuffer(config->_cl_queue, config->h_result, CL_TRUE, CL_MAP_WRITE, 0, buffer_size, 0, NULL, NULL, &err);
	gpu_check_error(err, "clEnqueueMapBuffer() for pinned_h_result failed.");
	clEnqueueReadBuffer(config->_cl_queue, config->d_dv, CL_TRUE, data_offset, buffer_size - data_offset, config->pinned_h_result + data_offset, 0, NULL, NULL);
	// release memory
	clEnqueueUnmapMemObject(config->_cl_queue, config->h_result, config->pinned_h_result, 0, NULL, NULL);
	clReleaseMemObject(config->h_v);
	clReleaseMemObject(config->h_result);
}

/* compute the slope vector for the package nodes	*/
void slope_fn_pack_gpu(gpu_config_t *config, grid_model_t *model, double *v, grid_model_vector_t *p, double *dv)
{
	int i, j;
	/* sum of the currents(power values)	*/
	double psum;
	
	/* shortcuts	*/
	package_RC_t *pk = &model->pack;
	thermal_config_t *c = &model->config;
	layer_t *l = model->layers;
	int nl = model->n_layers;
	int nr = model->rows;
	int nc = model->cols;
	int spidx, hsidx, metalidx, c4idx, subidx, solderidx, pcbidx;
	
	/* pointer to the starting address of the extra nodes	*/
	double *x = v + nl*nr*nc;

	
	if (!model->config.model_secondary) {
		spidx = nl - DEFAULT_PACK_LAYERS + LAYER_SP;
		hsidx = nl - DEFAULT_PACK_LAYERS + LAYER_SINK;
	} else {
		spidx = nl - DEFAULT_PACK_LAYERS - SEC_PACK_LAYERS + LAYER_SP;
		hsidx = nl - DEFAULT_PACK_LAYERS - SEC_PACK_LAYERS + LAYER_SINK;
		metalidx = nl - DEFAULT_PACK_LAYERS - SEC_PACK_LAYERS - SEC_CHIP_LAYERS + LAYER_METAL;
		c4idx = nl - DEFAULT_PACK_LAYERS - SEC_PACK_LAYERS - SEC_CHIP_LAYERS + LAYER_C4;
		subidx = nl - SEC_PACK_LAYERS + LAYER_SUB;
		solderidx = nl - SEC_PACK_LAYERS + LAYER_SOLDER;
		pcbidx = nl - SEC_PACK_LAYERS + LAYER_PCB;		
	}
	

	/* sink outer north/south	*/
	psum = (c->ambient - x[SINK_N])/(pk->r_hs_per + pk->r_amb_per) + 
		   (x[SINK_C_N] - x[SINK_N])/(pk->r_hs2_y + pk->r_hs);
	dv[nl*nr*nc + SINK_N] = psum / (pk->c_hs_per + pk->c_amb_per);
	psum = (c->ambient - x[SINK_S])/(pk->r_hs_per + pk->r_amb_per) + 
		   (x[SINK_C_S] - x[SINK_S])/(pk->r_hs2_y + pk->r_hs);
	dv[nl*nr*nc + SINK_S] = psum / (pk->c_hs_per + pk->c_amb_per);

	/* sink outer west/east	*/
	psum = (c->ambient - x[SINK_W])/(pk->r_hs_per + pk->r_amb_per) + 
		   (x[SINK_C_W] - x[SINK_W])/(pk->r_hs2_x + pk->r_hs);
	dv[nl*nr*nc + SINK_W] = psum / (pk->c_hs_per + pk->c_amb_per);
	psum = (c->ambient - x[SINK_E])/(pk->r_hs_per + pk->r_amb_per) + 
		   (x[SINK_C_E] - x[SINK_E])/(pk->r_hs2_x + pk->r_hs);
	dv[nl*nr*nc + SINK_E] = psum / (pk->c_hs_per + pk->c_amb_per);

	/* sink inner north/south	*/
	/* partition r_hs1_y among all the nc grid cells. edge cell has half the ry	*/
	psum = 0.0;
	for(j=0; j < nc; j++)
		psum += (A3D(v,hsidx,0,j,nl,nr,nc) - x[SINK_C_N]);
	psum /= (l[hsidx].ry / 2.0 + nc * pk->r_hs1_y);
	psum += (c->ambient - x[SINK_C_N])/(pk->r_hs_c_per_y + pk->r_amb_c_per_y) + 
			(x[SP_N] - x[SINK_C_N])/pk->r_sp_per_y +
			(x[SINK_N] - x[SINK_C_N])/(pk->r_hs2_y + pk->r_hs);
	dv[nl*nr*nc + SINK_C_N] = psum / (pk->c_hs_c_per_y + pk->c_amb_c_per_y);

	psum = 0.0;
	for(j=0; j < nc; j++)
		psum += (A3D(v,hsidx,nr-1,j,nl,nr,nc) - x[SINK_C_S]);
	psum /= (l[hsidx].ry / 2.0 + nc * pk->r_hs1_y);
	psum += (c->ambient - x[SINK_C_S])/(pk->r_hs_c_per_y + pk->r_amb_c_per_y) + 
			(x[SP_S] - x[SINK_C_S])/pk->r_sp_per_y +
			(x[SINK_S] - x[SINK_C_S])/(pk->r_hs2_y + pk->r_hs);
	dv[nl*nr*nc + SINK_C_S] = psum / (pk->c_hs_c_per_y + pk->c_amb_c_per_y);

	/* sink inner west/east	*/
	/* partition r_hs1_x among all the nr grid cells. edge cell has half the rx	*/
	psum = 0.0;
	for(i=0; i < nr; i++)
		psum += (A3D(v,hsidx,i,0,nl,nr,nc) - x[SINK_C_W]);
	psum /= (l[hsidx].rx / 2.0 + nr * pk->r_hs1_x);
	psum += (c->ambient - x[SINK_C_W])/(pk->r_hs_c_per_x + pk->r_amb_c_per_x) + 
			(x[SP_W] - x[SINK_C_W])/pk->r_sp_per_x +
			(x[SINK_W] - x[SINK_C_W])/(pk->r_hs2_x + pk->r_hs);
	dv[nl*nr*nc + SINK_C_W] = psum / (pk->c_hs_c_per_x + pk->c_amb_c_per_x);

	psum = 0.0;
	for(i=0; i < nr; i++)
		psum += (A3D(v,hsidx,i,nc-1,nl,nr,nc) - x[SINK_C_E]);
	psum /= (l[hsidx].rx / 2.0 + nr * pk->r_hs1_x);
	psum += (c->ambient - x[SINK_C_E])/(pk->r_hs_c_per_x + pk->r_amb_c_per_x) + 
			(x[SP_E] - x[SINK_C_E])/pk->r_sp_per_x +
			(x[SINK_E] - x[SINK_C_E])/(pk->r_hs2_x + pk->r_hs);
	dv[nl*nr*nc + SINK_C_E] = psum / (pk->c_hs_c_per_x + pk->c_amb_c_per_x);

	/* spreader north/south	*/
	/* partition r_sp1_y among all the nc grid cells. edge cell has half the ry	*/
	psum = 0.0;
	for(j=0; j < nc; j++)
		psum += (A3D(v,spidx,0,j,nl,nr,nc) - x[SP_N]);
	psum /= (l[spidx].ry / 2.0 + nc * pk->r_sp1_y);
	psum += (x[SINK_C_N] - x[SP_N])/pk->r_sp_per_y;
	dv[nl*nr*nc + SP_N] = psum / pk->c_sp_per_y;

	psum = 0.0;
	for(j=0; j < nc; j++)
		psum += (A3D(v,spidx,nr-1,j,nl,nr,nc) - x[SP_S]);
	psum /= (l[spidx].ry / 2.0 + nc * pk->r_sp1_y);
	psum += (x[SINK_C_S] - x[SP_S])/pk->r_sp_per_y;
	dv[nl*nr*nc + SP_S] = psum / pk->c_sp_per_y;

	/* spreader west/east	*/
	/* partition r_sp1_x among all the nr grid cells. edge cell has half the rx	*/
	psum = 0.0;
	for(i=0; i < nr; i++)
		psum += (A3D(v,spidx,i,0,nl,nr,nc) - x[SP_W]);
	psum /= (l[spidx].rx / 2.0 + nr * pk->r_sp1_x);
	psum += (x[SINK_C_W] - x[SP_W])/pk->r_sp_per_x;
	dv[nl*nr*nc + SP_W] = psum / pk->c_sp_per_x;

	psum = 0.0;
	for(i=0; i < nr; i++)
		psum += (A3D(v,spidx,i,nc-1,nl,nr,nc) - x[SP_E]);
	psum /= (l[spidx].rx / 2.0 + nr * pk->r_sp1_x);
	psum += (x[SINK_C_E] - x[SP_E])/pk->r_sp_per_x;
	dv[nl*nr*nc + SP_E] = psum / pk->c_sp_per_x;
	
	if (model->config.model_secondary) {
		/* PCB outer north/south	*/
		psum = (c->ambient - x[PCB_N])/(pk->r_amb_sec_per) + 
			   (x[PCB_C_N] - x[PCB_N])/(pk->r_pcb2_y + pk->r_pcb);
		dv[nl*nr*nc + PCB_N] = psum / (pk->c_pcb_per + pk->c_amb_sec_per);
		psum = (c->ambient - x[PCB_S])/(pk->r_amb_sec_per) + 
			   (x[PCB_C_S] - x[PCB_S])/(pk->r_pcb2_y + pk->r_pcb);
		dv[nl*nr*nc + PCB_S] = psum / (pk->c_pcb_per + pk->c_amb_sec_per);
  	
		/* PCB outer west/east	*/
		psum = (c->ambient - x[PCB_W])/(pk->r_amb_sec_per) + 
			   (x[PCB_C_W] - x[PCB_W])/(pk->r_pcb2_x + pk->r_pcb);
		dv[nl*nr*nc + PCB_W] = psum / (pk->c_pcb_per + pk->c_amb_sec_per);
		psum = (c->ambient - x[PCB_E])/(pk->r_amb_sec_per) + 
			   (x[PCB_C_E] - x[PCB_E])/(pk->r_pcb2_x + pk->r_pcb);
		dv[nl*nr*nc + PCB_E] = psum / (pk->c_pcb_per + pk->c_amb_sec_per);
  	
		/* PCB inner north/south	*/
		/* partition r_pcb1_y among all the nc grid cells. edge cell has half the ry	*/
		psum = 0.0;
		for(j=0; j < nc; j++)
			psum += (A3D(v,pcbidx,0,j,nl,nr,nc) - x[PCB_C_N]);
		psum /= (l[pcbidx].ry / 2.0 + nc * pk->r_pcb1_y);
		psum += (c->ambient - x[PCB_C_N])/(pk->r_amb_sec_c_per_y) + 
				(x[SOLDER_N] - x[PCB_C_N])/pk->r_pcb_c_per_y +
				(x[PCB_N] - x[PCB_C_N])/(pk->r_pcb2_y + pk->r_pcb);
		dv[nl*nr*nc + PCB_C_N] = psum / (pk->c_pcb_c_per_y + pk->c_amb_sec_c_per_y);
  	
		psum = 0.0;
		for(j=0; j < nc; j++)
			psum += (A3D(v,pcbidx,nr-1,j,nl,nr,nc) - x[PCB_C_S]);
		psum /= (l[pcbidx].ry / 2.0 + nc * pk->r_pcb1_y);
		psum += (c->ambient - x[PCB_C_S])/(pk->r_amb_sec_c_per_y) + 
				(x[SOLDER_S] - x[PCB_C_S])/pk->r_pcb_c_per_y +
				(x[PCB_S] - x[PCB_C_S])/(pk->r_pcb2_y + pk->r_pcb);
		dv[nl*nr*nc + PCB_C_S] = psum / (pk->c_pcb_c_per_y + pk->c_amb_sec_c_per_y);
  	
  	/* PCB inner west/east	*/
		/* partition r_pcb1_x among all the nr grid cells. edge cell has half the rx	*/
		psum = 0.0;
		for(i=0; i < nr; i++)
			psum += (A3D(v,pcbidx,i,0,nl,nr,nc) - x[PCB_C_W]);
		psum /= (l[pcbidx].rx / 2.0 + nr * pk->r_pcb1_x);
		psum += (c->ambient - x[PCB_C_W])/(pk->r_amb_sec_c_per_x) + 
				(x[SOLDER_W] - x[PCB_C_W])/pk->r_pcb_c_per_x +
				(x[PCB_W] - x[PCB_C_W])/(pk->r_pcb2_x + pk->r_pcb);
		dv[nl*nr*nc + PCB_C_W] = psum / (pk->c_pcb_c_per_x + pk->c_amb_sec_c_per_x);
  	
		psum = 0.0;
		for(i=0; i < nr; i++)
			psum += (A3D(v,pcbidx,i,nc-1,nl,nr,nc) - x[PCB_C_E]);
		psum /= (l[pcbidx].rx / 2.0 + nr * pk->r_pcb1_x);
		psum += (c->ambient - x[PCB_C_E])/(pk->r_amb_sec_c_per_x) + 
				(x[SOLDER_E] - x[PCB_C_E])/pk->r_pcb_c_per_x +
				(x[PCB_E] - x[PCB_C_E])/(pk->r_pcb2_x + pk->r_pcb);
		dv[nl*nr*nc + PCB_C_E] = psum / (pk->c_pcb_c_per_x + pk->c_amb_sec_c_per_x);
  	
		/* solder ball north/south	*/
		/* partition r_solder1_y among all the nc grid cells. edge cell has half the ry	*/
		psum = 0.0;
		for(j=0; j < nc; j++)
			psum += (A3D(v,solderidx,0,j,nl,nr,nc) - x[SOLDER_N]);
		psum /= (l[solderidx].ry / 2.0 + nc * pk->r_solder1_y);
		psum += (x[PCB_C_N] - x[SOLDER_N])/pk->r_pcb_c_per_y;
		dv[nl*nr*nc + SOLDER_N] = psum / pk->c_solder_per_y;
  	
		psum = 0.0;
		for(j=0; j < nc; j++)
			psum += (A3D(v,solderidx,nr-1,j,nl,nr,nc) - x[SOLDER_S]);
		psum /= (l[solderidx].ry / 2.0 + nc * pk->r_solder1_y);
		psum += (x[PCB_C_S] - x[SOLDER_S])/pk->r_pcb_c_per_y;
		dv[nl*nr*nc + SOLDER_S] = psum / pk->c_solder_per_y;
  	
		/* solder ball west/east	*/
		/* partition r_solder1_x among all the nr grid cells. edge cell has half the rx	*/
		psum = 0.0;
		for(i=0; i < nr; i++)
			psum += (A3D(v,solderidx,i,0,nl,nr,nc) - x[SOLDER_W]);
		psum /= (l[solderidx].rx / 2.0 + nr * pk->r_solder1_x);
		psum += (x[PCB_C_W] - x[SOLDER_W])/pk->r_pcb_c_per_x;
		dv[nl*nr*nc + SOLDER_W] = psum / pk->c_solder_per_x;
  	
		psum = 0.0;
		for(i=0; i < nr; i++)
			psum += (A3D(v,solderidx,i,nc-1,nl,nr,nc) - x[SOLDER_E]);
		psum /= (l[solderidx].rx / 2.0 + nr * pk->r_solder1_x);
		psum += (x[PCB_C_E] - x[SOLDER_E])/pk->r_pcb_c_per_x;
		dv[nl*nr*nc + SOLDER_E] = psum / pk->c_solder_per_x;
		
		/* package substrate north/south	*/
		/* partition r_sub1_y among all the nc grid cells. edge cell has half the ry	*/
		psum = 0.0;
		for(j=0; j < nc; j++)
			psum += (A3D(v,subidx,0,j,nl,nr,nc) - x[SUB_N]);
		psum /= (l[subidx].ry / 2.0 + nc * pk->r_sub1_y);
		psum += (x[SOLDER_N] - x[SUB_N])/pk->r_solder_per_y;
		dv[nl*nr*nc + SUB_N] = psum / pk->c_sub_per_y;
  	
		psum = 0.0;
		for(j=0; j < nc; j++)
			psum += (A3D(v,subidx,nr-1,j,nl,nr,nc) - x[SUB_S]);
		psum /= (l[subidx].ry / 2.0 + nc * pk->r_sub1_y);
		psum += (x[SOLDER_S] - x[SUB_S])/pk->r_solder_per_y;
		dv[nl*nr*nc + SUB_S] = psum / pk->c_sub_per_y;
  	
		/* sub ball west/east	*/
		/* partition r_sub1_x among all the nr grid cells. edge cell has half the rx	*/
		psum = 0.0;
		for(i=0; i < nr; i++)
			psum += (A3D(v,subidx,i,0,nl,nr,nc) - x[SUB_W]);
		psum /= (l[subidx].rx / 2.0 + nr * pk->r_sub1_x);
		psum += (x[SOLDER_W] - x[SUB_W])/pk->r_solder_per_x;
		dv[nl*nr*nc + SUB_W] = psum / pk->c_sub_per_x;
  	
		psum = 0.0;
		for(i=0; i < nr; i++)
			psum += (A3D(v,subidx,i,nc-1,nl,nr,nc) - x[SUB_E]);
		psum /= (l[subidx].rx / 2.0 + nr * pk->r_sub1_x);
		psum += (x[SOLDER_E] - x[SUB_E])/pk->r_solder_per_x;
		dv[nl*nr*nc + SUB_E] = psum / pk->c_sub_per_x;
	}
}

